# Arquitetura Completa do Modelo - Explica√ß√£o Detalhada

## üìã Vis√£o Geral

**Modelo Base:** U-Net  
**Encoder:** EfficientNet-B4 (pr√©-treinado ImageNet)  
**Decoder:** Blocos de upsampling com skip connections  
**Modifica√ß√£o:** Wavelet DWT 2D no primeiro skip connection  
**Sa√≠da:** 2 canais (Exsudatos + Hemorragias)  
**Fun√ß√£o de Ativa√ß√£o:** **Sigmoid** (n√£o Softmax!)  

---

## üèóÔ∏è 1. Estrutura Geral (U-Net)

```
INPUT (3, 512, 512)                                    OUTPUT (2, 512, 512)
      |                                                         ‚Üë
      ‚Üì                                                         |
  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                             ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
  ‚îÇ ENCODER ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Skip 0 (3, 512, 512) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí ‚îÇ DECODER ‚îÇ
  ‚îÇ         ‚îÇ                                             ‚îÇ         ‚îÇ
  ‚îÇ Efficient‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Skip 1 (48, 256, 256) + WAVELET ‚Üí‚îÇ  Blocks ‚îÇ
  ‚îÇ Net-B4  ‚îÇ                                             ‚îÇ         ‚îÇ
  ‚îÇ         ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Skip 2 (56, 128, 128) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ         ‚îÇ
  ‚îÇ         ‚îÇ                                             ‚îÇ         ‚îÇ
  ‚îÇ         ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Skip 3 (160, 64, 64) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ         ‚îÇ
  ‚îÇ         ‚îÇ                                             ‚îÇ         ‚îÇ
  ‚îÇ         ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Skip 4 (272, 32, 32) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ         ‚îÇ
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       |                                                       ‚Üë
       ‚îî‚îÄ‚îÄ‚îÄ Bottleneck (448, 16, 16) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Pontos-chave:**
- Encoder **reduz** resolu√ß√£o espacial e **aumenta** n√∫mero de canais
- Decoder **aumenta** resolu√ß√£o espacial e **reduz** n√∫mero de canais
- Skip connections permitem que detalhes de alta resolu√ß√£o fluam diretamente para o decoder
- **WAVELET atua APENAS no Skip 1** (primeiro skip ap√≥s entrada)

---

## üî¨ 2. Encoder Detalhado (EfficientNet-B4)

O EfficientNet-B4 √© dividido em **5 features** extra√≠das em diferentes profundidades:

```python
# Sa√≠das do encoder em cada n√≠vel:
features = [
    features[0]: (3, 512, 512)    # Input original (RGB)
    features[1]: (48, 256, 256)   # ‚Üê WAVELET APLICADO AQUI!
    features[2]: (56, 128, 128)   
    features[3]: (160, 64, 64)    
    features[4]: (272, 32, 32)    
]

# Bottleneck (sa√≠da final do encoder):
bottleneck: (448, 16, 16)
```

### Como funciona o EfficientNet-B4:

1. **Conv Stem:** (3, 512, 512) ‚Üí (48, 256, 256)
   - Primeira convolu√ß√£o, reduz resolu√ß√£o pela metade

2. **MBConv Blocks (Mobile Inverted Bottleneck):**
   - Sequ√™ncia de blocos que aplicam:
     - **Expand:** Aumenta canais temporariamente
     - **Depthwise Conv:** Convolu√ß√£o eficiente por canal
     - **Squeeze-Excitation (SE):** Aten√ß√£o nos canais
     - **Project:** Reduz canais de volta
   
3. **Progressive Downsampling:**
   - A cada bloco, reduz resolu√ß√£o espacial
   - Aumenta n√∫mero de canais (extrai features mais complexas)

---

## üåä 3. Wavelet Enhancement no Skip 1

**Localiza√ß√£o:** Entre `features[1]` do encoder e decoder  
**Input:** (48, 256, 256) - primeira feature ap√≥s downsampling  
**Output:** (48, 256, 256) - mesma dimens√£o, mas enriquecida com edges

### Processo Detalhado:

```python
# 1. Input original do skip
skip1_original = encoder.features[1]  # [B, 48, 256, 256]

# 2. Aplicar DWT 2D (Discrete Wavelet Transform - Haar)
for cada canal (48 canais):
    LL, LH, HL, HH = pywt.dwt2(canal, 'haar')
    # LL: Low-Low (aproxima√ß√£o) - 128√ó128 - DESCARTADO
    # LH: Low-High (bordas horizontais) - 128√ó128 - USADO
    # HL: High-Low (bordas verticais) - 128√ó128 - USADO
    # HH: High-High (bordas diagonais) - 128√ó128 - USADO

# 3. Upsample wavelets de volta para 256√ó256
LH_upsampled = F.interpolate(LH, size=(256, 256))  # [B, 48, 256, 256]
HL_upsampled = F.interpolate(HL, size=(256, 256))  # [B, 48, 256, 256]
HH_upsampled = F.interpolate(HH, size=(256, 256))  # [B, 48, 256, 256]

# 4. Concatenar com skip original
concatenated = torch.cat([
    skip1_original,  # [B, 48, 256, 256]
    LH_upsampled,    # [B, 48, 256, 256]
    HL_upsampled,    # [B, 48, 256, 256]
    HH_upsampled     # [B, 48, 256, 256]
], dim=1)  # Resultado: [B, 192, 256, 256]

# 5. Reduzir canais de volta para 48 (Conv 1√ó1 + BN + ReLU)
skip1_enhanced = WaveletModule(concatenated)  # [B, 48, 256, 256]
```

### Por que funciona?

- **LH, HL, HH** capturam **bordas em diferentes dire√ß√µes**
- Exsudatos e hemorragias t√™m **bordas bem definidas**
- Wavelet extrai essas informa√ß√µes de alta frequ√™ncia
- Modelo consegue detectar melhor les√µes pequenas e detalhadas

---

## üîÑ 4. Decoder e Skip Connections

### Como as skip connections se unem:

```python
# Decoder Block (exemplo simplificado)
def decoder_block(decoder_input, skip_connection):
    # 1. Upsample decoder (dobra resolu√ß√£o)
    up = upsample(decoder_input)  # Ex: (128, 32, 32) ‚Üí (128, 64, 64)
    
    # 2. Concatenar com skip connection
    concat = torch.cat([up, skip_connection], dim=1)  # Soma canais
    
    # 3. Convolu√ß√µes para processar
    out = conv1(concat)
    out = bn1(out)
    out = relu(out)
    out = conv2(out)
    out = bn2(out)
    out = relu(out)
    
    return out
```

### Fluxo Completo do Decoder:

```
Bottleneck (448, 16, 16)
    ‚Üì upsample + concat skip4
Block 4: (272, 32, 32) ‚Üí (160, 32, 32)
    ‚Üì upsample + concat skip3
Block 3: (160, 64, 64) ‚Üí (56, 64, 64)
    ‚Üì upsample + concat skip2
Block 2: (56, 128, 128) ‚Üí (48, 128, 128)
    ‚Üì upsample + concat skip1 (COM WAVELET!)
Block 1: (48, 256, 256) ‚Üí (16, 256, 256)
    ‚Üì upsample + concat skip0
Block 0: (3, 512, 512) ‚Üí (16, 512, 512)
    ‚Üì
Segmentation Head
```

---

## üéØ 5. Sa√≠da e Ativa√ß√£o (CRITICAL!)

### Segmentation Head:

```python
# √öltima camada
self.segmentation_head = nn.Conv2d(
    in_channels=16,
    out_channels=2,  # ‚Üê 2 CLASSES (Exsudatos, Hemorragias)
    kernel_size=3,
    padding=1
)

# Forward
logits = self.segmentation_head(decoder_output)  # [B, 2, 512, 512]
```

### ‚ö†Ô∏è SIGMOID vs SOFTMAX - Diferen√ßa CRUCIAL:

**N√£o usamos Softmax! Usamos SIGMOID!**

```python
# Durante predi√ß√£o:
probs = torch.sigmoid(logits)  # [B, 2, 512, 512]

# Canal 0: Probabilidade de Exsudato (independente)
# Canal 1: Probabilidade de Hemorragia (independente)
```

### Por que SIGMOID e n√£o SOFTMAX?

**Com Softmax (ERRADO para este caso):**
```python
probs = F.softmax(logits, dim=1)
# Se P(exsudato) = 0.8 ‚Üí P(hemorragia) = 0.2
# Classes s√£o MUTUAMENTE EXCLUSIVAS
# Um pixel S√ì pode ser exsudato OU hemorragia
```

**Com Sigmoid (CORRETO!):**
```python
probs = torch.sigmoid(logits)
# P(exsudato) = 0.8 e P(hemorragia) = 0.7 √© V√ÅLIDO!
# Classes s√£o INDEPENDENTES
# Um pixel PODE ter exsudato E hemorragia simultaneamente
```

### Por que precisamos dessa independ√™ncia?

1. **Les√µes podem se sobrepor** na imagem
2. **Background** √© impl√≠cito: `P(background) = (1 - P(exsudato)) * (1 - P(hemorragia))`
3. **Multi-label classification**: Cada classe √© bin√°ria independente

---

## üìä 6. Loss Function

```python
# Usamos Binary Cross-Entropy (BCE) + Dice Loss
# N√ÉO usamos Categorical Cross-Entropy (que exigiria Softmax)

# Para cada classe:
bce_loss = -[y * log(œÉ(x)) + (1-y) * log(1-œÉ(x))]

# Dice Loss (para cada classe separadamente):
dice_loss = 1 - (2 * |X ‚à© Y|) / (|X| + |Y|)

# Total:
total_loss = Œ± * bce_loss + Œ≤ * dice_loss
```

---

## üîç 7. Fluxo Completo de Dados (Passo a Passo)

### Input: Imagem RGB (512√ó512)

```python
# 1. Entrada
image = (3, 512, 512)  # RGB normalizada

# 2. Encoder (EfficientNet-B4)
encoder_out = encoder(image)
# features[0] = (3, 512, 512)
# features[1] = (48, 256, 256)  ‚Üê Ser√° modificado!
# features[2] = (56, 128, 128)
# features[3] = (160, 64, 64)
# features[4] = (272, 32, 32)

# 3. HOOK: Modificar features[1] com Wavelet
original_skip1 = features[1]  # (48, 256, 256)
enhanced_skip1 = wavelet_module(original_skip1)  # (48, 256, 256) + edges
features[1] = enhanced_skip1  # Substitui!

# 4. Decoder (com skips modificadas)
x = bottleneck  # (448, 16, 16)

# Decoder Block 4
x = upsample(x)  # (448, 32, 32)
x = concat(x, features[4])  # (448 + 272, 32, 32) = (720, 32, 32)
x = conv_blocks(x)  # (160, 32, 32)

# Decoder Block 3
x = upsample(x)  # (160, 64, 64)
x = concat(x, features[3])  # (160 + 160, 64, 64) = (320, 64, 64)
x = conv_blocks(x)  # (56, 64, 64)

# Decoder Block 2
x = upsample(x)  # (56, 128, 128)
x = concat(x, features[2])  # (56 + 56, 128, 128) = (112, 128, 128)
x = conv_blocks(x)  # (48, 128, 128)

# Decoder Block 1 - USA SKIP COM WAVELET!
x = upsample(x)  # (48, 256, 256)
x = concat(x, features[1])  # (48 + 48, 256, 256) = (96, 256, 256)
x = conv_blocks(x)  # (16, 256, 256)

# Decoder Block 0
x = upsample(x)  # (16, 512, 512)
x = concat(x, features[0])  # (16 + 3, 512, 512) = (19, 512, 512)
x = conv_blocks(x)  # (16, 512, 512)

# 5. Segmentation Head
logits = segmentation_head(x)  # (2, 512, 512)

# 6. Ativa√ß√£o (SIGMOID!)
probs = torch.sigmoid(logits)  # (2, 512, 512)
# probs[0] = Probabilidade de Exsudato para cada pixel
# probs[1] = Probabilidade de Hemorragia para cada pixel
```

---

## üìà 8. P√≥s-Processamento e M√©tricas

### Binariza√ß√£o:

```python
threshold = 0.5
pred_exsudatos = (probs[0] > threshold).float()  # (512, 512) - bin√°rio
pred_hemorragias = (probs[1] > threshold).float()  # (512, 512) - bin√°rio
```

### C√°lculo de Dice:

```python
# Para cada classe separadamente:
def dice_score(pred, target):
    intersection = (pred * target).sum()
    union = pred.sum() + target.sum()
    dice = (2 * intersection) / (union + 1e-8)
    return dice

dice_exsudatos = dice_score(pred_exsudatos, gt_exsudatos)
dice_hemorragias = dice_score(pred_hemorragias, gt_hemorragias)
dice_mean = (dice_exsudatos + dice_hemorragias) / 2
```

---

## üéì 9. Resumo Conceitual

### Analogia com uma f√°brica:

1. **Encoder (EfficientNet-B4):** Linha de montagem que **extrai features**
   - In√≠cio: Imagem simples (3 cores)
   - Fim: Representa√ß√£o complexa (448 features)

2. **Skip Connections:** Tubos laterais que **preservam detalhes**
   - Permitem que informa√ß√£o de alta resolu√ß√£o "pule" etapas
   - Essencial para reconstru√ß√£o precisa

3. **Wavelet no Skip 1:** Departamento de **controle de qualidade de bordas**
   - Detecta bordas finas e detalhes
   - Melhora detec√ß√£o de les√µes pequenas

4. **Decoder:** Linha de reconstru√ß√£o que **reconstr√≥i a imagem**
   - Combina features profundas (sem√¢ntica) com detalhes (skips)
   - Gera mapa de probabilidades

5. **Sigmoid:** Decis√£o final **independente para cada classe**
   - N√£o for√ßa competi√ß√£o entre classes
   - Permite sobreposi√ß√£o de les√µes

---

## üìä 10. Compara√ß√£o: Baseline vs Wavelet

### Baseline (sem CLAHE):

```
Input ‚Üí Encoder ‚Üí Skips (normais) ‚Üí Decoder ‚Üí Output
                                      ‚Üì
                                  Dice: 0.6501
```

### Com Wavelet Skip 1:

```
Input ‚Üí Encoder ‚Üí Skip1 + Wavelet ‚Üí Decoder ‚Üí Output
                   ‚Üë                   ‚Üì
              Extrai bordas        Dice: 0.6721 (+3.4%)
```

### Por que Skip 1 especificamente?

- **Alta resolu√ß√£o** (256√ó256): Detalhes preservados
- **N√£o muito profundo**: Ainda captura informa√ß√£o espacial
- **N√£o muito raso**: J√° tem features abstra√≠das
- **Equil√≠brio perfeito** entre sem√¢ntica e detalhes espaciais

---

## üîß 11. Implementa√ß√£o T√©cnica (Hooks)

### Como integramos o Wavelet sem modificar o encoder?

```python
class UnetWaveletSkip1(nn.Module):
    def __init__(self, ...):
        self.base_model = smp.Unet(...)  # UNet original
        self.wavelet_skip1 = WaveletSkipConnection(48)  # M√≥dulo wavelet
        self.register_hooks()  # Registra hook
    
    def register_hooks(self):
        # Hook intercepta sa√≠da do encoder
        self.base_model.encoder.register_forward_hook(
            self._custom_forward_hook
        )
    
    def _custom_forward_hook(self, module, input, output):
        # output = [features[0], features[1], ..., features[4]]
        features = list(output)
        
        # Modifica apenas features[1]
        features[1] = self.wavelet_skip1(features[1])
        
        return tuple(features)  # Retorna modificado
```

**Vantagem:** N√£o precisamos reescrever o encoder inteiro!

---

## üìù 12. Par√¢metros do Modelo

```python
Total de par√¢metros: 19,310,994
  - Encoder (EfficientNet-B4): ~15M par√¢metros
  - Decoder: ~4M par√¢metros
  - Wavelet Skip: 9,312 par√¢metros (+0.05%)
  - Segmentation Head: ~300 par√¢metros
```

**Overhead do Wavelet:** Praticamente zero!

---

## üéØ 13. Por que isso funciona?

1. **EfficientNet-B4:** Encoder robusto, pr√©-treinado, eficiente
2. **U-Net:** Arquitetura comprovada para segmenta√ß√£o m√©dica
3. **Wavelet:** Extrai informa√ß√£o de alta frequ√™ncia (bordas, texturas)
4. **Skip 1:** Localiza√ß√£o ideal para enriquecimento de detalhes
5. **Sigmoid:** Permite multi-label (les√µes podem coexistir)
6. **Dice + BCE Loss:** Lida bem com classes desbalanceadas

---

## üöÄ 14. Pr√≥ximos Passos Poss√≠veis

1. **Wavelet em m√∫ltiplos skips** (Skip 1 + Skip 2)
2. **Diferentes wavelets** (Daubechies, Biorthogonal)
3. **Attention mechanisms** nos skips
4. **Multi-scale inference** (TTA melhorado)
5. **Ensemble com outros encoders** (ResNet, DenseNet)

---

## üìö Refer√™ncias

- **U-Net:** Ronneberger et al., "U-Net: Convolutional Networks for Biomedical Image Segmentation"
- **EfficientNet:** Tan & Le, "EfficientNet: Rethinking Model Scaling for CNNs"
- **Wavelet:** Mallat, "A Wavelet Tour of Signal Processing"
- **Segmentation Models PyTorch:** https://github.com/qubvel/segmentation_models.pytorch

---

**√öltima atualiza√ß√£o:** 2026-01-05  
**Performance:** Test Dice = **0.6721** (Exsudatos: 0.7275, Hemorragias: 0.6167)
