# ROP Segmentation - TAPI INRID

Projeto de segmentaÃ§Ã£o de lesÃµes em imagens de retina para detecÃ§Ã£o de Retinopatia da Prematuridade (ROP).

## ğŸ¯ Melhor Resultado

**Test Dice: 0.6448** (Ensemble 5-fold + TTA)

- **Arquitetura:** EfficientNet-B4 + UNet
- **Dataset:** 54 treino / 27 teste
- **PrÃ©-processamento:** CLAHE LAB L-channel
- **Ensemble:** 5 folds + 4 transformaÃ§Ãµes TTA

## ğŸ“ Estrutura do Projeto

```
tapi_inrid/
â”œâ”€â”€ ğŸ“‚ configs/              # ConfiguraÃ§Ãµes do projeto
â”œâ”€â”€ ğŸ“‚ data_factory/         # Dataset loaders e transforms
â”œâ”€â”€ ğŸ“‚ models/               # Arquiteturas de modelos
â”œâ”€â”€ ğŸ“‚ utils/                # FunÃ§Ãµes utilitÃ¡rias
â”‚
â”œâ”€â”€ ğŸ“‚ experiments/          # Scripts de treinamento dos experimentos
â”‚   â”œâ”€â”€ README.md            # Guia dos experimentos
â”‚   â”œâ”€â”€ verify_baseline.py   # Reproduzir baseline (0.6448) !
â”‚   â””â”€â”€ train_*.py           # Outros experimentos
â”‚
â”œâ”€â”€ ğŸ“‚ docs/                 # DocumentaÃ§Ã£o
â”‚   â”œâ”€â”€ README.md            # Guia da documentaÃ§Ã£o
â”‚   â””â”€â”€ EXPERIMENTOS.md      # AnÃ¡lise completa experimentos
â”‚
â”œâ”€â”€ ğŸ“‚ logs/                 # Logs de todos os treinamentos
â”‚   â””â”€â”€ README.md            # Guia dos logs
â”‚
â”œâ”€â”€ ğŸ“‚ outputs/              # Resultados e checkpoints
â”‚   â”œâ”€â”€ checkpoints/         # Modelos treinados
â”‚   â”‚   â””â”€â”€ baseline_verify/ # Melhor modelo (0.6448)
â”‚   â””â”€â”€ *.json               # Resultados em JSON
â”‚
â”œâ”€â”€ ğŸ“‚ notebooks/            # Jupyter notebooks para anÃ¡lise
â”œâ”€â”€ ğŸ“‚ A. Segmentation/      # Dataset original
â”‚
â”œâ”€â”€ main.py                  # Script principal de treinamento
â””â”€â”€ requirements.txt         # DependÃªncias Python
```

## ğŸš€ Quick Start

### 1. InstalaÃ§Ã£o
```bash
pip install -r requirements.txt
```

### 2. Reproduzir Melhor Resultado
```bash
python experiments/verify_baseline.py
```

### 3. Avaliar Test Set
```bash
python experiments/evaluate_test_ensemble.py
```

## ğŸ“Š Experimentos Realizados

Total: **10 experimentos completos** + 3 interrompidos

### Ranking de Resultados

| # | Experimento | Test Dice | Î” vs Baseline | Status |
|---|-------------|-----------|---------------|--------|
| 1 | **Baseline (EfficientNet-B4 + UNet)** | **0.6448** | **0.00%** | âœ… **MELHOR** |
| 2 | Extreme Augmentation | 0.6422 | -0.40% | âŒ |
| 3 | ASPP Bottleneck | 0.6230 | -3.30% | âŒ |
| 4 | Attention Gates (Fixed) | 0.6182 | -4.13% | âŒ |
| 5 | Moderate Augmentation | 0.6009 | -6.80% | âŒ |
| 6 | ASPP Decoder | 0.5947 | -7.77% | âŒ |
| 7 | Green Channel CLAHE | CV: 0.5212 | -5.59% | âŒ Interrompido |
| 8 | Attention Gates (Buggy) | 0.5109 | -20.69% | âŒ Bug |
| 9 | Boundary Loss | 0.0100 | -99.0% | âŒ Falha |
| - | Frangi Enhancement | N/A | N/A | âŒ Abandonado |

**Ver anÃ¡lise completa:** [docs/EXPERIMENTOS.md](docs/EXPERIMENTOS.md)

## ğŸ” Principal Descoberta

**Dataset muito pequeno (54 imagens) limita melhorias:**

âŒ Arquiteturas complexas â†’ Overfitting  
âŒ AugmentaÃ§Ã£o avanÃ§ada â†’ Piora resultados  
âŒ Processamento de imagem â†’ Perde informaÃ§Ã£o  
âœ… **Baseline simples Ã© o melhor para este dataset**

## ğŸ“– DocumentaÃ§Ã£o

- **[docs/EXPERIMENTOS.md](docs/EXPERIMENTOS.md)** - AnÃ¡lise detalhada de todos os experimentos
  - ConfiguraÃ§Ãµes completas
  - Resultados e mÃ©tricas
  - AnÃ¡lises tÃ©cnicas profundas
  - Insights e liÃ§Ãµes aprendidas
  
- **[experiments/README.md](experiments/README.md)** - Guia dos scripts de treinamento

- **[logs/README.md](logs/README.md)** - Guia dos logs de treinamento

## Arquitetura do Baseline

O melhor resultado usa os princÃ­pios:

### 1. **Config** (`configs/config.py`)
- Gerencia todos os hiperparÃ¢metros
- Define paths do dataset
- ConfiguraÃ§Ãµes de prÃ©-processamento (CLAHE)
- ParÃ¢metros de treino

### 2. **DataFactory** (`data_factory/data_factory.py`)
- Mapeia estrutura de diretÃ³rios do dataset
- Cria DataFrame com metadados (paths de imagens e mÃ¡scaras)
- Prepara splits para cross-validation com GroupKFold
- **Nunca carrega imagens, apenas metadados**

### 3. **ROPDataset** (`data_factory/ROP_dataset.py`)
- PyTorch Dataset
- Carrega imagens (.jpg) e mÃ¡scaras (.tiff)
- Aplica CLAHE (Contrast Limited Adaptive Histogram Equalization)
- Combina mÃºltiplas mÃ¡scaras (Hard + Soft Exudates)
- Suporta data augmentation com Albumentations

### 4. **TrainAndEvalWorker** (`train_and_val_worker.py`)
- Gerencia treinamento e validaÃ§Ã£o
- Cria DataLoaders
- Instancia modelos (U-Net, U-Net++, DeepLabV3+)
- Calcula mÃ©tricas (Dice, IoU)
- Salva checkpoints

### 5. **Main** (`main.py`)
- Orquestra o pipeline completo
- Apenas instancia classes e chama mÃ©todos
- **Sem lÃ³gica de treino ou carregamento de dados**

## Dataset

O projeto utiliza o dataset **IDRiD** (Indian Diabetic Retinopathy Image Dataset):

```
A. Segmentation/
â”œâ”€â”€ 1. Original Images/
â”‚   â”œâ”€â”€ a. Training Set/
â”‚   â””â”€â”€ b. Testing Set/
â””â”€â”€ 2. All Segmentation Groundtruths/
    â”œâ”€â”€ a. Training Set/
    â”‚   â”œâ”€â”€ 2. Haemorrhages/
    â”‚   â”œâ”€â”€ 3. Hard Exudates/
    â”‚   â””â”€â”€ 4. Soft Exudates/
    â””â”€â”€ b. Testing Set/
        â”œâ”€â”€ 2. Haemorrhages/
        â”œâ”€â”€ 3. Hard Exudates/
        â””â”€â”€ 4. Soft Exudates/
```

### Classes Consideradas
- **Exudatos**: Hard e Soft Exudates combinados em uma Ãºnica classe
- **Hemorragias**: Hemorrhages

**Nota**: Microaneurismas e Optic Disc sÃ£o ignorados.

## InstalaÃ§Ã£o

```bash
# Criar ambiente virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# Instalar dependÃªncias
pip install -r requirements.txt
```

## Uso

### 1. ExploraÃ§Ã£o de Dados

Abra o notebook de anÃ¡lise exploratÃ³ria:

```bash
jupyter notebook notebooks/data_exploration.ipynb
```

O notebook mostra:
- DistribuiÃ§Ã£o de classes
- Exemplos de imagens e mÃ¡scaras
- Efeito do prÃ©-processamento CLAHE
- EstatÃ­sticas do dataset

### 2. Treinamento

Execute o pipeline principal:

```bash
python main.py
```

O script irÃ¡:
1. Criar metadados do dataset
2. Preparar splits para 5-fold cross-validation
3. Treinar modelo U-Net com encoder ResNet34
4. Avaliar no conjunto de teste

### 3. ConfiguraÃ§Ã£o

Edite [configs/config.py](configs/config.py) para ajustar:
- Tamanho das imagens
- HiperparÃ¢metros de treino
- Arquitetura do modelo
- ConfiguraÃ§Ãµes de CLAHE

## CaracterÃ­sticas TÃ©cnicas

### PrÃ©-processamento
- **CLAHE**: Aplicado no canal L (luminosidade) do espaÃ§o LAB
- **NormalizaÃ§Ã£o**: ImageNet mean/std
- **Resize**: 512x512 (configurÃ¡vel)

### Data Augmentation
- Horizontal/Vertical flip
- Random rotation (90Â°)
- ShiftScaleRotate
- Elastic/Grid/Optical distortion

### Modelo
- **Arquitetura**: U-Net (padrÃ£o)
- **Encoder**: ResNet34 prÃ©-treinado (ImageNet)
- **Loss**: Binary Cross Entropy with Logits
- **MÃ©tricas**: Dice Score, IoU

### Cross-Validation
- **GroupKFold** (5 folds)
- Agrupamento por paciente para evitar data leakage

## Estrutura de SaÃ­da

```
outputs/
â”œâ”€â”€ checkpoints/
â”‚   â”œâ”€â”€ best_model_fold1.pth
â”‚   â”œâ”€â”€ best_model_fold2.pth
â”‚   â””â”€â”€ ...
â””â”€â”€ logs/
    â””â”€â”€ (logs de treinamento)
```

## MÃ©tricas

- **Dice Score**: MÃ©trica principal
- **IoU (Jaccard Index)**: MÃ©trica complementar
- Calculadas por classe e mÃ©dia geral

