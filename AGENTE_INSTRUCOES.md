# InstruÃ§Ãµes para Agente - Projeto SegmentaÃ§Ã£o ROP com Wavelets

## ğŸ“‹ CONTEXTO DO PROJETO

### VisÃ£o Geral
Projeto de pesquisa de mestrado focado em **segmentaÃ§Ã£o de lesÃµes retinopatia** usando **U-Net + EfficientNet + Wavelet Skip Connections**.

**Dataset:** INRID (Indian Neonatal Retinopathy Database)
- 81 imagens totais (54 train/val + 27 test)
- Classes: Exsudatos e Hemorragias (multi-label)
- ResoluÃ§Ã£o original: 4288Ã—2848 pixels
- ResoluÃ§Ã£o de treino: 512Ã—512 pixels

**Melhor Modelo Atual:**
- Arquitetura: UNet + EfficientNet-B4 + Wavelet DWT (Haar) no primeiro skip
- Test Dice: **0.6721**
  - Exsudatos: 0.7275
  - Hemorragias: 0.6167
- Ganho vs baseline: +4.6%

---

## ğŸ—‚ï¸ ESTRUTURA DO PROJETO (OBRIGATÃ“RIA)

```
tapi_inrid/
â”œâ”€â”€ configs/                    # ConfiguraÃ§Ãµes do projeto
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ config.py              # Classe Config central
â”‚
â”œâ”€â”€ data_factory/              # Datasets e data loaders
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_factory.py        # DataFactory (cria datasets)
â”‚   â””â”€â”€ ROP_dataset.py         # Dataset customizado (ROPDataset)
â”‚
â”œâ”€â”€ docs/                      # ğŸ“ DOCUMENTAÃ‡ÃƒO (sempre aqui!)
â”‚   â”œâ”€â”€ ARQUITETURA_EXPLICADA.md
â”‚   â”œâ”€â”€ TUTORIAL_WAVELETS.md
â”‚   â””â”€â”€ SUGESTOES_SLIDES.md
â”‚
â”œâ”€â”€ experiments/               # ğŸ§ª SCRIPTS DE EXPERIMENTOS
â”‚   â”œâ”€â”€ train_efficientnet_b1.py
â”‚   â”œâ”€â”€ train_efficientnet_b2.py
â”‚   â”œâ”€â”€ ...
â”‚   â”œâ”€â”€ train_wavelet_skip1.py
â”‚   â””â”€â”€ exp_XXX_description.py  # NOVO formato (enumerar!)
â”‚
â”œâ”€â”€ logs/                      # Logs de treinamento
â”‚   â”œâ”€â”€ training_efficientnet_b1.log
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ models/                    # Arquiteturas de modelos
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ unet_efficientnet.py
â”‚   â””â”€â”€ unet_wavelet_skip1.py
â”‚
â”œâ”€â”€ notebooks/                 # Jupyter notebooks (exploraÃ§Ã£o)
â”‚   â”œâ”€â”€ data_exploration.ipynb
â”‚   â””â”€â”€ visualize_wavelet_predictions.ipynb
â”‚
â”œâ”€â”€ outputs/                   # SaÃ­das de treinamento
â”‚   â”œâ”€â”€ checkpoints/           # Modelos salvos (.pth)
â”‚   â”‚   â”œâ”€â”€ best_model_fold1.pth
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ cv_splits.json         # âš ï¸ FROZEN! NÃ£o alterar
â”‚   â””â”€â”€ logs/                  # Logs detalhados (TensorBoard, etc.)
â”‚
â”œâ”€â”€ tests/                     # ğŸ§ª TESTES (criar ANTES de experimentos!)
â”‚   â”œâ”€â”€ test_config.py
â”‚   â”œâ”€â”€ test_dataset.py
â”‚   â”œâ”€â”€ test_model.py
â”‚   â””â”€â”€ test_exp_XXX.py        # Teste do experimento XXX
â”‚
â”œâ”€â”€ utils/                     # UtilitÃ¡rios
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ utils.py               # set_seed, mÃ©tricas, etc.
â”‚
â”œâ”€â”€ main.py                    # Script principal (treinamento base)
â”œâ”€â”€ train_and_val_worker.py    # Worker de treinamento
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“ CONVENÃ‡Ã•ES DE NOMENCLATURA

### Experimentos (`experiments/`)

**FORMATO OBRIGATÃ“RIO (a partir de agora):**
```
exp_XXX_brief_description.py

Onde:
- XXX = nÃºmero sequencial (001, 002, 003, ...)
- brief_description = descriÃ§Ã£o curta (snake_case)

Exemplos:
âœ… exp_001_wavelet_skip2.py          # Testar wavelet no skip 2
âœ… exp_002_attention_module.py        # Adicionar attention
âœ… exp_003_multiscale_wavelet.py      # Wavelet multi-escala
âœ… exp_004_clahe_rgb_only.py          # CLAHE apenas em R+B

âŒ train_new_model.py                 # NÃ£o enumera
âŒ test_wavelet.py                    # Confunde com testes
âŒ experiment.py                      # NÃ£o descritivo
```

### Logs (`logs/`)
```
training_exp_XXX_brief_description.log

Exemplo:
âœ… training_exp_001_wavelet_skip2.log
```

### Testes (`tests/`)
```
test_exp_XXX.py  # Testa o experimento XXX
test_<component>.py  # Testa componente especÃ­fico

Exemplos:
âœ… test_exp_001.py      # Testa exp_001_wavelet_skip2.py
âœ… test_dataset.py      # Testa ROPDataset
âœ… test_model.py        # Testa arquitetura
```

### Modelos (`models/`)
```
<architecture>_<variant>.py

Exemplos:
âœ… unet_efficientnet.py          # U-Net base com EfficientNet
âœ… unet_wavelet_skip1.py         # U-Net com wavelet no skip 1
âœ… unet_attention.py             # U-Net com attention
```

### DocumentaÃ§Ã£o (`docs/`)
```
<TOPIC>_<TYPE>.md

Exemplos:
âœ… ARQUITETURA_EXPLICADA.md
âœ… TUTORIAL_WAVELETS.md
âœ… EXPERIMENTOS_REALIZADOS.md
âœ… INSTRUCOES_DEPLOYMENT.md
```

---

## ğŸ”„ WORKFLOW DE EXPERIMENTOS (OBRIGATÃ“RIO)

### Passo 1: Criar Teste PRIMEIRO
```bash
# SEMPRE criar teste antes do experimento!

# Arquivo: tests/test_exp_XXX.py
"""
Teste do experimento XXX: <descriÃ§Ã£o>

Valida:
- ConfiguraÃ§Ã£o carrega corretamente
- Dataset Ã© criado sem erros
- Modelo inicializa
- Forward pass funciona
- Backward pass funciona (sem NaN, inf)
- MÃ©tricas sÃ£o calculadas
"""

import pytest
import torch
from experiments.exp_XXX_description import (
    create_model,
    create_config,
    # outras funÃ§Ãµes
)

def test_config_creation():
    """Valida criaÃ§Ã£o de config."""
    config = create_config()
    assert config is not None
    assert config.img_size == 512
    # ...

def test_model_initialization():
    """Valida inicializaÃ§Ã£o do modelo."""
    model = create_model()
    assert model is not None
    
    # Contar parÃ¢metros
    total_params = sum(p.numel() for p in model.parameters())
    print(f"Total params: {total_params}")
    
def test_forward_pass():
    """Valida forward pass."""
    model = create_model()
    x = torch.randn(2, 3, 512, 512)
    
    with torch.no_grad():
        output = model(x)
    
    assert output.shape == (2, 2, 512, 512)  # [B, C, H, W]
    assert not torch.isnan(output).any()
    assert not torch.isinf(output).any()

def test_backward_pass():
    """Valida backward pass."""
    model = create_model()
    x = torch.randn(2, 3, 512, 512)
    target = torch.randint(0, 2, (2, 2, 512, 512)).float()
    
    output = model(x)
    loss = torch.nn.functional.binary_cross_entropy_with_logits(output, target)
    
    loss.backward()
    
    # Verificar gradientes
    for name, param in model.named_parameters():
        if param.grad is not None:
            assert not torch.isnan(param.grad).any(), f"NaN in {name}"
            assert not torch.isinf(param.grad).any(), f"Inf in {name}"

if __name__ == "__main__":
    pytest.main([__file__, "-v"])
```

### Passo 2: Criar Experimento
```bash
# Arquivo: experiments/exp_XXX_description.py
"""
Experimento XXX: <DescriÃ§Ã£o Detalhada>

Objetivo:
- <objetivo principal>

HipÃ³tese:
- <hipÃ³tese a ser testada>

MudanÃ§as vs Baseline:
- <listar mudanÃ§as>

Baseline:
- <modelo de referÃªncia>

Resultados Esperados:
- <expectativa de ganho>
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import torch
import torch.nn as nn
from configs.config import Config
from data_factory.data_factory import DataFactory
from models.unet_new_variant import UNetNewVariant
from utils.utils import set_seed, DiceLoss
# ...

def create_config():
    """Cria configuraÃ§Ã£o do experimento."""
    config = Config()
    
    # ModificaÃ§Ãµes especÃ­ficas
    config.experiment_name = "exp_XXX_description"
    config.num_epochs = 100
    config.learning_rate = 1e-4
    # ... outras configs
    
    return config

def create_model(config):
    """Cria modelo do experimento."""
    model = UNetNewVariant(
        encoder_name=config.encoder_name,
        encoder_weights='imagenet',
        in_channels=3,
        classes=config.num_classes
    )
    return model

def main():
    """FunÃ§Ã£o principal de treinamento."""
    # Config
    config = create_config()
    set_seed(config.random_state)
    
    # Data
    data_factory = DataFactory(config)
    # ... criar dataloaders
    
    # Model
    model = create_model(config)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)
    
    # Training loop
    # ... implementar
    
    # Logging
    # ... salvar resultados

if __name__ == "__main__":
    main()
```

### Passo 3: Executar Teste
```bash
# SEMPRE rodar teste ANTES de treinar!
pytest tests/test_exp_XXX.py -v

# Se passar â†’ prosseguir
# Se falhar â†’ corrigir antes de treinar
```

### Passo 4: Executar Experimento
```bash
# Com logging
python experiments/exp_XXX_description.py 2>&1 | tee logs/training_exp_XXX_description.log

# Monitorar progresso
tail -f logs/training_exp_XXX_description.log
```

### Passo 5: Documentar Resultados
```bash
# Atualizar docs/EXPERIMENTOS_REALIZADOS.md

## Experimento XXX: <DescriÃ§Ã£o>

**Data:** YYYY-MM-DD

**Objetivo:**
- <objetivo>

**ConfiguraÃ§Ã£o:**
```python
learning_rate = 1e-4
num_epochs = 100
# ...
```

**Resultados:**
| MÃ©trica | Baseline | Exp XXX | Ganho |
|---------|----------|---------|-------|
| Test Dice | 0.6721 | 0.XXXX | +X.X% |
| Exsudatos | 0.7275 | 0.XXXX | +X.X% |
| Hemorragias | 0.6167 | 0.XXXX | +X.X% |

**AnÃ¡lise:**
- <conclusÃµes>

**Status:** âœ… Sucesso / âŒ Falhou / âš ï¸ Resultados inconclusivos
```

---

## âš™ï¸ USO DA CLASSE CONFIG (OBRIGATÃ“RIO)

### Regra Principal
**NUNCA criar variÃ¡veis globais para configuraÃ§Ãµes em experimentos!**

A classe `Config` em `configs/config.py` jÃ¡ contÃ©m todos os hiperparÃ¢metros padrÃ£o.
Cada experimento deve:
1. Criar um objeto `Config()`
2. Modificar APENAS os parÃ¢metros que diferem do padrÃ£o
3. Usar `config.atributo` em todo o cÃ³digo

### ParÃ¢metros DisponÃ­veis na Config

```python
# configs/config.py - ParÃ¢metros principais

@dataclass
class Config:
    # Dataset
    dataset_root: str = "/home/lucas/mestrado/tapi_inrid/A. Segmentation"
    classes: List[str] = ["exudates", "haemorrhages"]
    
    # Image preprocessing
    image_size: tuple = (512, 512)
    apply_clahe: bool = True  # NOTA: Setar False (jÃ¡ provou que piora)
    clahe_clip_limit: float = 2.0
    
    # Training
    batch_size: int = 8
    num_epochs: int = 50
    learning_rate: float = 1e-3
    weight_decay: float = 1e-5
    
    # Model
    model_name: str = "unet"
    encoder_name: str = "efficientnet-b4"
    encoder_weights: str = "imagenet"
    num_classes: int = 2
    
    # Loss
    loss_type: str = "dice_focal"
    
    # Scheduler
    scheduler_type: str = "onecycle"  # ou "plateau"
    early_stopping_patience: int = 20
    
    # Cross-validation
    n_folds: int = 5
    random_state: int = 42
    
    # Paths
    output_dir: str = "outputs"
    checkpoint_dir: str  # auto-gerado em __post_init__
```

### Exemplo de FunÃ§Ã£o create_config()

```python
def create_config():
    """
    Cria configuraÃ§Ã£o do experimento.
    
    Usa a classe Config como BASE e modifica apenas o necessÃ¡rio.
    NUNCA criar variÃ¡veis globais separadas!
    """
    config = Config()
    
    # === IdentificaÃ§Ã£o ===
    config.experiment_name = "exp_XXX_description"
    
    # === ModificaÃ§Ãµes especÃ­ficas deste experimento ===
    config.apply_clahe = False  # Desabilitar CLAHE
    config.num_epochs = 100     # Mais Ã©pocas que padrÃ£o
    config.learning_rate = 1e-4 # LR diferente
    
    # === Para experimentos com novos parÃ¢metros ===
    # Adicionar dinamicamente (dataclass permite)
    config.patch_size = 512
    config.patch_overlap = 50
    
    # === Checkpoint dir especÃ­fico ===
    config.checkpoint_dir = os.path.join(config.output_dir, "checkpoints", "exp_XXX")
    os.makedirs(config.checkpoint_dir, exist_ok=True)
    
    return config
```

### âŒ ERRADO - VariÃ¡veis Globais

```python
# NÃƒO FAZER ISSO!
BATCH_SIZE = 8
NUM_EPOCHS = 100
LEARNING_RATE = 1e-4
ENCODER_NAME = 'efficientnet-b4'

def main():
    model = smp.Unet(encoder_name=ENCODER_NAME, ...)  # âŒ
    optimizer = Adam(lr=LEARNING_RATE)  # âŒ
```

### âœ… CORRETO - Usar Config

```python
def create_config():
    config = Config()
    config.batch_size = 8
    config.num_epochs = 100
    config.learning_rate = 1e-4
    return config

def main():
    config = create_config()
    
    model = smp.Unet(encoder_name=config.encoder_name, ...)  # âœ…
    optimizer = Adam(lr=config.learning_rate)  # âœ…
    
    for epoch in range(config.num_epochs):  # âœ…
        ...
```

### BenefÃ­cios

1. **ConsistÃªncia**: Todos os experimentos usam a mesma estrutura
2. **Rastreabilidade**: FÃ¡cil salvar config em JSON para reprodutibilidade
3. **Valores padrÃ£o**: NÃ£o precisa redefinir tudo, sÃ³ o que muda
4. **Evita bugs**: ParÃ¢metros centralizados, nÃ£o espalhados pelo cÃ³digo

---

## ğŸš¨ ERROS COMUNS A EVITAR (LIÃ‡Ã•ES APRENDIDAS)

### 1. **PyTorch 2.6+ e Checkpoints**
```python
# âŒ ERRADO (causa erro em PyTorch 2.6+)
checkpoint = torch.load(path, map_location=device)

# âœ… CORRETO
checkpoint = torch.load(path, map_location=device, weights_only=False)

# âœ… MELHOR (se checkpoint tem dict)
checkpoint = torch.load(path, map_location=device, weights_only=False)
model.load_state_dict(checkpoint['model_state_dict'])
```

**RazÃ£o:** PyTorch 2.6+ mudou default de `weights_only` para `True` por seguranÃ§a.

### 2. **Estrutura de Checkpoint**
```python
# âŒ ERRADO (assume que checkpoint Ã‰ o state_dict)
model.load_state_dict(checkpoint)

# âœ… CORRETO (checkpoint Ã© dict com 'model_state_dict')
model.load_state_dict(checkpoint['model_state_dict'])

# âœ… SEMPRE salvar assim:
torch.save({
    'epoch': epoch,
    'model_state_dict': model.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
    'loss': loss,
    'metrics': metrics
}, path)
```

### 3. **Multi-Label vs Multi-Class**
```python
# Nosso problema Ã© MULTI-LABEL (nÃ£o multi-class)!

# âŒ ERRADO (Softmax para multi-class)
output = torch.softmax(logits, dim=1)  # Classes mutuamente exclusivas

# âœ… CORRETO (Sigmoid para multi-label)
output = torch.sigmoid(logits)  # Classes independentes

# âŒ ERRADO (CrossEntropy para multi-class)
loss = nn.CrossEntropyLoss()

# âœ… CORRETO (BCEWithLogitsLoss para multi-label)
loss = nn.BCEWithLogitsLoss()
```

**RazÃ£o:** Pixel pode ter ambas classes (exsudato E hemorragia).

### 4. **CLAHE: Deve Aplicar em LAB, nÃ£o RGB**
```python
# âŒ ERRADO (aplicar CLAHE diretamente em RGB)
clahe = cv2.createCLAHE(...)
for i in range(3):
    image[:,:,i] = clahe.apply(image[:,:,i])

# âœ… CORRETO (aplicar apenas em canal L do LAB)
lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)
l, a, b = cv2.split(lab)
l_clahe = clahe.apply(l)
lab_clahe = cv2.merge([l_clahe, a, b])
image_clahe = cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2RGB)
```

**LiÃ§Ã£o:** CLAHE em todos os canais RGB causa oversegmentation (comprovado experimentalmente: 0.6428 com CLAHE vs 0.6501 sem CLAHE).

### 5. **GroupKFold e Data Leakage**
```python
# âŒ ERRADO (KFold normal - pode colocar imagens do mesmo paciente em train e val)
from sklearn.model_selection import KFold
kfold = KFold(n_splits=5)

# âœ… CORRETO (GroupKFold - garante pacientes separados)
from sklearn.model_selection import GroupKFold
kfold = GroupKFold(n_splits=5)

# Uso:
for fold, (train_idx, val_idx) in enumerate(kfold.split(X, y, groups=patient_ids)):
    # train_idx e val_idx tÃªm pacientes diferentes
```

**RazÃ£o:** Mesmo paciente tem imagens correlacionadas. GroupKFold evita vazamento.

### 6. **Cross-Validation Splits: FREEZE!**
```python
# âš ï¸ IMPORTANTE: Salvar splits no primeiro experimento
import json

cv_splits = {
    'fold1': {'train': [...], 'val': [...]},
    # ...
}

with open('outputs/cv_splits.json', 'w') as f:
    json.dump(cv_splits, f)

# âœ… Todos os experimentos futuros DEVEM usar o mesmo split!
with open('outputs/cv_splits.json', 'r') as f:
    cv_splits = json.load(f)
```

**RazÃ£o:** ComparaÃ§Ã£o justa entre experimentos.

### 7. **NormalizaÃ§Ã£o: ImageNet Stats**
```python
# âœ… SEMPRE usar mesma normalizaÃ§Ã£o do encoder prÃ©-treinado
mean = [0.485, 0.456, 0.406]  # ImageNet mean
std = [0.229, 0.224, 0.225]   # ImageNet std

# Albumentations
A.Normalize(mean=mean, std=std)

# Desnormalizar para visualizaÃ§Ã£o
image_denorm = image * std + mean
image_denorm = np.clip(image_denorm, 0, 1)
```

### 8. **TTA (Test-Time Augmentation): MÃ©dia, nÃ£o VotaÃ§Ã£o**
```python
# âŒ ERRADO (votaÃ§Ã£o para segmentaÃ§Ã£o)
predictions = [model(aug(x)) > 0.5 for aug in augs]
final = (sum(predictions) > len(predictions) // 2).float()

# âœ… CORRETO (mÃ©dia de probabilidades)
predictions = [torch.sigmoid(model(aug(x))) for aug in augs]
final = torch.stack(predictions).mean(dim=0)
final_binary = (final > 0.5).float()
```

### 9. **Dice Loss: SuavizaÃ§Ã£o Ã© Crucial**
```python
# âŒ ERRADO (divisÃ£o por zero)
dice = (2 * intersection) / (pred.sum() + gt.sum())

# âœ… CORRETO (adicionar epsilon)
dice = (2 * intersection + 1e-8) / (pred.sum() + gt.sum() + 1e-8)

# âœ… MELHOR (epsilon maior para estabilidade)
dice = (2 * intersection + 1.0) / (pred.sum() + gt.sum() + 1.0)
```

### 10. **Masks: Valores 0 ou 255 â†’ Normalizar para 0 ou 1**
```python
# âŒ ERRADO (assumir que mask jÃ¡ estÃ¡ em [0, 1])
mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
mask_tensor = torch.from_numpy(mask)  # Valores 0 ou 255!

# âœ… CORRETO
mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
mask = (mask > 127).astype(np.float32)  # Binarizar para {0.0, 1.0}
mask_tensor = torch.from_numpy(mask)
```

### 11. **Encoding de Features: Congelar ou NÃ£o?**
```python
# Nosso caso: NÃƒO congelamos encoder

# âŒ Se fosse congelar (nÃ£o fazemos):
for param in model.encoder.parameters():
    param.requires_grad = False

# âœ… Deixamos treinar end-to-end (fazemos):
# (nada a fazer, padrÃ£o Ã© trainable)

# âš ï¸ Usar encoder_weights='imagenet' (prÃ©-treinado)
model = UNet(encoder_name='efficientnet-b4', encoder_weights='imagenet')
```

**DecisÃ£o:** Fine-tuning completo funcionou melhor que frozen encoder.

### 12. **DependÃªncias Faltando (Hugging Face Hub)**
```python
# âŒ Erro comum ao carregar modelos prÃ©-treinados:
# ModuleNotFoundError: No module named 'huggingface_hub'

# âœ… SEMPRE ter no requirements.txt:
torch>=2.0.0
torchvision>=0.15.0
segmentation-models-pytorch>=0.3.0
albumentations>=1.3.0
opencv-python>=4.7.0
numpy>=1.23.0
pandas>=1.5.0
scikit-learn>=1.2.0
matplotlib>=3.7.0
seaborn>=0.12.0
tqdm>=4.65.0
pyyaml>=6.0
huggingface-hub>=0.16.0  # â† IMPORTANTE!
ipywidgets>=8.0.0        # Para notebooks
```

---

## ğŸ§¬ CONTEXTO TÃ‰CNICO COMPLETO

### Arquitetura Atual (Wavelet Skip 1)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      INPUT: [B, 3, 512, 512]                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               ENCODER: EfficientNet-B4 (ImageNet)               â”‚
â”‚                                                                 â”‚
â”‚  features[0]: [B,   48, 512, 512]  â† Skip 0                    â”‚
â”‚  features[1]: [B,   48, 256, 256]  â† Skip 1 (WAVELET AQUI!) âœ¨â”‚
â”‚  features[2]: [B,   80, 128, 128]  â† Skip 2                    â”‚
â”‚  features[3]: [B,  192,  64,  64]  â† Skip 3                    â”‚
â”‚  features[4]: [B,  448,  32,  32]  â† Skip 4                    â”‚
â”‚  bottleneck:  [B, 1792,  16,  16]  â† Bottleneck                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    WAVELET TRANSFORM (Hook)                     â”‚
â”‚                                                                 â”‚
â”‚  features[1]: [B, 48, 256, 256]                                â”‚
â”‚       â†“                                                         â”‚
â”‚  DWT 2D (Haar):                                                 â”‚
â”‚       â†“                                                         â”‚
â”‚  LL (descartado): [B, 48, 128, 128]  â† Redundante com skip     â”‚
â”‚  LH (horizontal):  [B, 48, 128, 128]  â† Bordas horizontais      â”‚
â”‚  HL (vertical):    [B, 48, 128, 128]  â† Bordas verticais        â”‚
â”‚  HH (diagonal):    [B, 48, 128, 128]  â† Bordas diagonais        â”‚
â”‚       â†“                                                         â”‚
â”‚  concat(LH, HL, HH): [B, 144, 128, 128]                        â”‚
â”‚       â†“                                                         â”‚
â”‚  upsample â†’ [B, 144, 256, 256]                                 â”‚
â”‚       â†“                                                         â”‚
â”‚  enhanced_skip = cat(features[1], wavelet)                     â”‚
â”‚                = [B, 192, 256, 256]                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DECODER: U-Net Upsampling                    â”‚
â”‚                                                                 â”‚
â”‚  NÃ­vel 5: [B, 1792, 16, 16] â†’ [B, 448, 32, 32] + skip[4]      â”‚
â”‚  NÃ­vel 4: [B, 640,  32, 32] â†’ [B, 192, 64, 64] + skip[3]      â”‚
â”‚  NÃ­vel 3: [B, 384,  64, 64] â†’ [B,  80, 128,128] + skip[2]     â”‚
â”‚  NÃ­vel 2: [B, 160, 128,128] â†’ [B,  48, 256,256] + skip[1]âœ¨   â”‚
â”‚  NÃ­vel 1: [B, 240, 256,256] â†’ [B,  48, 512,512] + skip[0]     â”‚
â”‚  NÃ­vel 0: [B,  96, 512,512] â†’ [B,  32, 512,512]               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   OUTPUT HEAD: Conv 1Ã—1                         â”‚
â”‚                                                                 â”‚
â”‚  [B, 32, 512, 512] â†’ [B, 2, 512, 512]                          â”‚
â”‚                                                                 â”‚
â”‚  Channel 0: Exsudatos (logits)                                 â”‚
â”‚  Channel 1: Hemorragias (logits)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SIGMOID (Inference)                          â”‚
â”‚                                                                 â”‚
â”‚  [B, 2, 512, 512] â†’ [B, 2, 512, 512] (probabilidades)          â”‚
â”‚                                                                 â”‚
â”‚  Threshold 0.5 â†’ MÃ¡scaras binÃ¡rias                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ParÃ¢metros:**
- Total: 19,345,186 params
- Encoder: ~18M
- Decoder: ~1.3M
- Wavelet overhead: +9,312 (+0.05%)

### HiperparÃ¢metros Finais

```python
# Data
img_size = 512
apply_clahe = False  # Removido (piorava performance)
num_classes = 2

# Training
batch_size = 4
num_epochs = 100
learning_rate = 1e-4

# Optimizer
optimizer = AdamW(
    params=model.parameters(),
    lr=1e-4,
    weight_decay=1e-4,
    betas=(0.9, 0.999)
)

# Loss
criterion = BCEWithLogitsLoss()

# Scheduler
scheduler = ReduceLROnPlateau(
    optimizer,
    mode='max',
    factor=0.5,
    patience=7,
    verbose=True,
    min_lr=1e-7
)

# Early Stopping
patience = 15

# Data Augmentation (Train)
transforms = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.VerticalFlip(p=0.5),
    A.RandomRotate90(p=0.5),
    A.ShiftScaleRotate(
        shift_limit=0.1,
        scale_limit=0.1,
        rotate_limit=15,
        p=0.5
    ),
    A.RandomBrightnessContrast(
        brightness_limit=0.2,
        contrast_limit=0.2,
        p=0.3
    ),
    A.GaussNoise(var_limit=(10.0, 50.0), p=0.2),
    A.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    ),
    ToTensorV2()
])

# Test-Time Augmentation
tta_transforms = [
    Original,
    HorizontalFlip,
    VerticalFlip,
    Rotate90,
    Rotate180,
    Rotate270
]

# Cross-Validation
cv_strategy = GroupKFold(n_splits=5)
cv_splits_path = 'outputs/cv_splits.json'  # FROZEN!
```

### MÃ©tricas

```python
def dice_score(pred, target, smooth=1.0):
    """
    Dice Score (F1 para segmentaÃ§Ã£o).
    
    Args:
        pred: [B, C, H, W] (probabilidades ou binÃ¡rias)
        target: [B, C, H, W] (ground truth)
        smooth: suavizaÃ§Ã£o (evita div por zero)
    
    Returns:
        dice: escalar [0, 1], 1 = perfeito
    """
    intersection = (pred * target).sum(dim=(2, 3))
    union = pred.sum(dim=(2, 3)) + target.sum(dim=(2, 3))
    
    dice = (2. * intersection + smooth) / (union + smooth)
    
    return dice.mean()  # MÃ©dia sobre batch e classes

# Uso:
pred_binary = (torch.sigmoid(output) > 0.5).float()
dice = dice_score(pred_binary, target)
```

---

## ğŸ“Š ESTADO ATUAL (RESULTADOS)

### ProgressÃ£o Completa

| Fase | Experimento | Test Dice | Ganho | Arquivo |
|------|-------------|-----------|-------|---------|
| 1 | B1 + CLAHE | 0.6272 | baseline | `train_efficientnet_b1.py` |
| 1 | B2 + CLAHE | 0.6265 | -0.1% | `train_efficientnet_b2.py` |
| 1 | B3 + CLAHE | 0.6257 | -0.2% | `train_efficientnet_b3.py` |
| 1 | **B4 + CLAHE** | **0.6428** | **+2.5%** | `train_efficientnet_b4_verify3.py` |
| 2 | B4 sem CLAHE | 0.6501 | +3.6% | `train_efficientnet_b4.py` |
| 3 | B4 Otimizado (100ep, 1e-4) | 0.6594 | +5.1% | `train_efficientnet_b4_verify3.py` |
| 4 | **Wavelet Skip 1** | **0.6721** | **+7.2%** | `train_wavelet_skip1.py` |

### Melhor Modelo (Wavelet Skip 1)

**Arquitetura:** `models/unet_wavelet_skip1.py`

**Resultados Detalhados:**
```
Cross-Validation (5-Fold):
- Fold 1: 0.6124
- Fold 2: 0.5789
- Fold 3: 0.6235
- Fold 4: 0.5918
- Fold 5: 0.5793
- Mean: 0.5972 Â± 0.0292

Test Set (Ensemble + TTA):
- Overall Dice: 0.6721
- Exsudatos: 0.7275
- Hemorragias: 0.6167

Ganhos vs Baseline (B4 + CLAHE):
- Overall: +4.6%
- Exsudatos: +3.4%
- Hemorragias: +6.0% (maior benefÃ­cio!)
```

**Checkpoints Salvos:**
```
outputs/checkpoints/
â”œâ”€â”€ best_model_fold1.pth
â”œâ”€â”€ best_model_fold2.pth
â”œâ”€â”€ best_model_fold3.pth
â”œâ”€â”€ best_model_fold4.pth
â””â”€â”€ best_model_fold5.pth
```

---

## ğŸš€ PRÃ“XIMOS PASSOS SUGERIDOS

### Experimentos Prontos para Testar

#### 1. **exp_001_wavelet_skip2.py** (Alta Prioridade)
**Objetivo:** Testar wavelet no skip 2 (128Ã—128)

**HipÃ³tese:** Skip 2 pode capturar features de mÃ©dio nÃ­vel (entre detalhes finos e contexto global).

**MudanÃ§as:**
```python
# Hook em features[2] ao invÃ©s de features[1]
# features[2]: [B, 80, 128, 128] â†’ wavelet: [B, 240, 64, 64]
```

**Expectativa:** Dice ~0.6650-0.6700 (provavelmente pior que skip 1)

---

#### 2. **exp_002_multiscale_wavelet.py** (MÃ©dia Prioridade)
**Objetivo:** Aplicar wavelet em MÃšLTIPLOS skips (1 e 2)

**HipÃ³tese:** Combinar bordas de alta e mÃ©dia resoluÃ§Ã£o pode ser complementar.

**MudanÃ§as:**
```python
# Hooks em features[1] E features[2]
# Skip 1: [B, 48, 256, 256] â†’ wavelet: [B, 144, 256, 256]
# Skip 2: [B, 80, 128, 128] â†’ wavelet: [B, 240, 128, 128]
```

**Expectativa:** Dice ~0.6750-0.6800 (+0.3-0.8%)

**Riscos:** Overhead de parÃ¢metros (+~20k), overfitting

---

#### 3. **exp_003_attention_module.py** (MÃ©dia Prioridade)
**Objetivo:** Adicionar Attention Gates no decoder

**HipÃ³tese:** Attention pode focar em regiÃµes de lesÃµes, reduzindo falsos positivos.

**MudanÃ§as:**
```python
# Adicionar Attention Gate antes de cada concatenaÃ§Ã£o de skip
class AttentionGate(nn.Module):
    def __init__(self, F_g, F_l, F_int):
        # ...
```

**Expectativa:** Dice ~0.6750-0.6800

**Riscos:** +5-10M parÃ¢metros, treinamento mais lento

---

#### 4. **exp_004_daubechies_wavelet.py** (Baixa Prioridade)
**Objetivo:** Comparar Haar vs Daubechies (db2, db4)

**HipÃ³tese:** Wavelets mais suaves podem capturar melhor bordas graduais.

**MudanÃ§as:**
```python
# wavelet='db2' ao invÃ©s de 'haar'
wavelet_transform = WaveletTransform(wavelet='db2')
```

**Expectativa:** Dice ~0.6700-0.6730 (similar ou ligeiramente pior)

---

#### 5. **exp_005_dice_bce_combined_loss.py** (MÃ©dia Prioridade)
**Objetivo:** Combinar Dice Loss + BCE Loss

**HipÃ³tese:** Dice foca em overlap, BCE em pixel-wise accuracy. CombinaÃ§Ã£o pode melhorar.

**MudanÃ§as:**
```python
# Loss hÃ­brida
loss = 0.5 * dice_loss(output, target) + 0.5 * bce_loss(output, target)
```

**Expectativa:** Dice ~0.6730-0.6770

---

#### 6. **exp_006_larger_image_size.py** (Alta Prioridade, mas Custoso)
**Objetivo:** Treinar com 768Ã—768 ao invÃ©s de 512Ã—512

**HipÃ³tese:** Maior resoluÃ§Ã£o preserva mais detalhes de lesÃµes pequenas.

**MudanÃ§as:**
```python
config.img_size = 768
config.batch_size = 2  # Reduzir por memÃ³ria GPU
```

**Expectativa:** Dice ~0.6800-0.6900 (+1-2%)

**Riscos:** 
- Requer 2.25x memÃ³ria GPU
- Treinamento 2x mais lento
- Pode precisar de +epochs

---

#### 7. **exp_007_test_time_scaling.py** (Baixa Prioridade)
**Objetivo:** Multi-scale testing (testar em 512, 768, 1024, averaging)

**HipÃ³tese:** Diferentes escalas capturam diferentes nÃ­veis de detalhe.

**MudanÃ§as:**
```python
# Inference em mÃºltiplas escalas
scales = [512, 768, 1024]
predictions = []
for scale in scales:
    img_scaled = resize(img, scale)
    pred = model(img_scaled)
    pred_resized = resize(pred, 512)
    predictions.append(pred_resized)
    
final_pred = torch.stack(predictions).mean(dim=0)
```

**Expectativa:** Dice ~0.6750-0.6800

---

### Experimentos de Longo Prazo

#### 8. **exp_008_self_supervised_pretraining.py**
**Objetivo:** PrÃ©-treinar encoder com task auto-supervisionada (e.g., rotation prediction, contrastive learning)

**Justificativa:** ImageNet Ã© natural images, nÃ£o mÃ©dicas. PrÃ©-treino especÃ­fico pode ajudar.

---

#### 9. **exp_009_ensemble_heterogeneous.py**
**Objetivo:** Ensemble de arquiteturas diferentes (B4 + B3 + Wavelet)

**Justificativa:** Diversidade de modelos melhora ensemble.

---

#### 10. **exp_010_pseudo_labeling.py**
**Objetivo:** Usar modelo treinado para pseudo-rotular imagens nÃ£o anotadas

**Justificativa:** Se houver imagens sem anotaÃ§Ã£o, aproveitar.

---

## ğŸ“ TEMPLATE PARA NOVOS DATASETS

Se criar dataset novo (e.g., para outro tipo de lesÃ£o), seguir estrutura:

```python
# Arquivo: data_factory/new_dataset.py

import torch
from torch.utils.data import Dataset
import cv2
import numpy as np
import albumentations as A
from pathlib import Path

class NewDataset(Dataset):
    """
    Dataset para <descriÃ§Ã£o>.
    
    Args:
        dataframe: pd.DataFrame com colunas:
            - 'image_path': caminho da imagem
            - 'mask_<class>_paths': lista de caminhos de mÃ¡scaras
            - 'patient_id': ID do paciente (para GroupKFold)
        config: objeto Config
        is_train: bool (True para augmentation)
        transform: transformaÃ§Ã£o customizada (opcional)
    """
    
    def __init__(self, dataframe, config, is_train=True, transform=None):
        self.dataframe = dataframe.reset_index(drop=True)
        self.config = config
        self.is_train = is_train
        
        # Criar transform se nÃ£o fornecido
        if transform is None:
            self.transform = self._get_default_transform()
        else:
            self.transform = transform
    
    def _get_default_transform(self):
        """Cria transformaÃ§Ã£o padrÃ£o."""
        if self.is_train:
            return A.Compose([
                A.Resize(self.config.img_size, self.config.img_size),
                A.HorizontalFlip(p=0.5),
                A.VerticalFlip(p=0.5),
                A.RandomRotate90(p=0.5),
                A.Normalize(
                    mean=[0.485, 0.456, 0.406],
                    std=[0.229, 0.224, 0.225]
                ),
                A.pytorch.ToTensorV2()
            ])
        else:
            return A.Compose([
                A.Resize(self.config.img_size, self.config.img_size),
                A.Normalize(
                    mean=[0.485, 0.456, 0.406],
                    std=[0.229, 0.224, 0.225]
                ),
                A.pytorch.ToTensorV2()
            ])
    
    def __len__(self):
        return len(self.dataframe)
    
    def __getitem__(self, idx):
        """
        Returns:
            dict:
                'image': torch.Tensor [3, H, W]
                'mask': torch.Tensor [num_classes, H, W]
                'image_name': str
        """
        row = self.dataframe.iloc[idx]
        
        # Carregar imagem
        image = cv2.imread(row['image_path'])
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # Carregar mÃ¡scaras
        masks = []
        for class_name in self.config.classes:
            mask_paths = row[f'mask_{class_name}_paths']
            
            if isinstance(mask_paths, list) and len(mask_paths) > 0:
                # Combinar mÃºltiplas mÃ¡scaras (OR lÃ³gico)
                combined_mask = np.zeros(image.shape[:2], dtype=np.float32)
                for mask_path in mask_paths:
                    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
                    mask = (mask > 127).astype(np.float32)
                    combined_mask = np.maximum(combined_mask, mask)
                masks.append(combined_mask)
            else:
                # Sem mÃ¡scara para essa classe
                masks.append(np.zeros(image.shape[:2], dtype=np.float32))
        
        masks = np.stack(masks, axis=-1)  # [H, W, num_classes]
        
        # Aplicar transformaÃ§Ãµes
        transformed = self.transform(image=image, mask=masks)
        
        return {
            'image': transformed['image'],  # [3, H, W]
            'mask': transformed['mask'].permute(2, 0, 1),  # [num_classes, H, W]
            'image_name': Path(row['image_path']).stem
        }
```

---

## ğŸ¯ PROTOCOLO DE COMUNICAÃ‡ÃƒO

### Como o Agente Deve Funcionar

1. **Sempre ler primeiro:**
   - `AGENTE_INSTRUCOES.md` (este arquivo)
   - `docs/EXPERIMENTOS_REALIZADOS.md` (histÃ³rico)
   - `outputs/cv_splits.json` (splits fixos)

2. **Antes de criar experimento:**
   - Verificar se experimento similar jÃ¡ foi feito
   - Verificar nÃºmero sequencial (Ãºltimo exp_XXX)
   - Criar teste PRIMEIRO (`tests/test_exp_XXX.py`)

3. **Ao criar arquivos:**
   - Seguir estrutura de pastas obrigatÃ³ria
   - Seguir convenÃ§Ãµes de nomenclatura
   - Adicionar docstrings detalhadas

4. **Durante treinamento:**
   - Sempre usar `2>&1 | tee logs/...` para logging
   - Monitorar com `tail -f`
   - Salvar checkpoints em `outputs/checkpoints/`

5. **ApÃ³s experimento:**
   - Documentar em `docs/EXPERIMENTOS_REALIZADOS.md`
   - Atualizar tabelas de comparaÃ§Ã£o
   - Se melhorar SOTA, destacar em bold

6. **ComunicaÃ§Ã£o com usuÃ¡rio:**
   - Ser conciso (1-3 frases para confirmaÃ§Ãµes simples)
   - Usar links markdown para arquivos: `[config.py](configs/config.py#L10)`
   - Evitar emojis (exceto quando usuÃ¡rio usa)
   - Explicar comandos tÃ©cnicos antes de executar

7. **Tratamento de erros:**
   - Sempre verificar este arquivo (seÃ§Ã£o "ERROS COMUNS")
   - Se erro novo, documentar para prÃ³ximos agentes
   - NÃ£o desistir facilmente, pesquisar soluÃ§Ãµes

---

## ğŸ“š DOCUMENTAÃ‡ÃƒO OBRIGATÃ“RIA

### Manter Atualizados

1. **docs/EXPERIMENTOS_REALIZADOS.md**
   - Todos os experimentos (sucesso ou falha)
   - Tabela comparativa
   - LiÃ§Ãµes aprendidas

2. **docs/ARQUITETURA_EXPLICADA.md**
   - Se modificar arquitetura, atualizar diagrama
   - Explicar mudanÃ§as

3. **README.md** (raiz)
   - Setup instructions
   - Quick start
   - Resultados principais

4. **requirements.txt**
   - Se adicionar biblioteca, documentar versÃ£o

---

## ğŸ”§ COMANDOS ÃšTEIS

### Setup Inicial
```bash
# Criar ambiente
conda create -n rop_seg python=3.10
conda activate rop_seg

# Instalar dependÃªncias
pip install -r requirements.txt

# Verificar GPU
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}')"
```

### Testes
```bash
# Testar tudo
pytest tests/ -v

# Testar especÃ­fico
pytest tests/test_exp_001.py -v

# Com coverage
pytest tests/ --cov=. --cov-report=html
```

### Treinamento
```bash
# Experimento com logging
python experiments/exp_XXX_description.py 2>&1 | tee logs/training_exp_XXX.log

# Monitorar progresso
tail -f logs/training_exp_XXX.log

# Em background (tmux)
tmux new -s exp_XXX
python experiments/exp_XXX.py 2>&1 | tee logs/training_exp_XXX.log
# Ctrl+B D para detach
```

### AnÃ¡lise de Resultados
```bash
# Extrair mÃ©tricas finais
tail -50 logs/training_exp_XXX.log | grep -E "(Test Results|Dice|Exudates|Haemorrhages)"

# Comparar com baseline
grep "Test Dice" logs/training_*.log

# Ver CV folds
python -c "import json; print(json.load(open('outputs/cv_splits.json')))"
```

### Limpeza
```bash
# Limpar checkpoints antigos (CUIDADO!)
# (Manter apenas best de cada fold)
find outputs/checkpoints/ -name "epoch_*.pth" -delete

# Limpar cache
rm -rf __pycache__ */__pycache__
```

---

## ğŸ“ RECURSOS DE APRENDIZADO

### Papers Implementados
1. **U-Net:** Ronneberger et al., 2015
2. **EfficientNet:** Tan & Le, 2019
3. **Wavelets em CNNs:** Liu et al., 2019
4. **Attention U-Net:** Oktay et al., 2018

### Tutoriais Criados
- `docs/TUTORIAL_WAVELETS.md` - Wavelet completo
- `docs/ARQUITETURA_EXPLICADA.md` - Arquitetura atual
- `docs/SUGESTOES_SLIDES.md` - Material para apresentaÃ§Ã£o

---

## âœ… CHECKLIST PARA NOVOS AGENTES

Antes de comeÃ§ar qualquer tarefa:

- [ ] Li `AGENTE_INSTRUCOES.md` completo
- [ ] Li `docs/EXPERIMENTOS_REALIZADOS.md` (histÃ³rico)
- [ ] Verifiquei estrutura de pastas
- [ ] Verifiquei Ãºltimo nÃºmero de experimento
- [ ] Entendi estado atual (melhor modelo, resultados)
- [ ] Sei onde salvar cada tipo de arquivo
- [ ] Sei como nomear arquivos
- [ ] Sei que preciso criar teste ANTES de experimento
- [ ] Sei como usar `outputs/cv_splits.json`
- [ ] Li seÃ§Ã£o "ERROS COMUNS"

---

## ğŸ†˜ TROUBLESHOOTING RÃPIDO

| Problema | SoluÃ§Ã£o |
|----------|---------|
| `ModuleNotFoundError: huggingface_hub` | `pip install huggingface-hub` |
| `RuntimeError: expected scalar type Float but found Byte` | Normalizar mask para [0, 1]: `mask = (mask > 127).astype(np.float32)` |
| `CUDA out of memory` | Reduzir batch_size em config.py |
| `NotImplementedError: weights_only` | Adicionar `weights_only=False` em `torch.load()` |
| `KeyError: 'model_state_dict'` | Checkpoint pode ser sÃ³ state_dict: `model.load_state_dict(checkpoint)` |
| `NaN loss during training` | Verificar normalizaÃ§Ã£o, learning rate, gradient clipping |
| Test Dice muito baixo (<0.5) | Verificar se usa Sigmoid (nÃ£o Softmax), se mask estÃ¡ [0,1] |
| CV splits diferentes entre runs | Usar `outputs/cv_splits.json` fixo, nÃ£o gerar novo |

---

## ğŸš¦ QUANDO PEDIR AJUDA AO USUÃRIO

**SEMPRE perguntar se:**
- Experimento novo nÃ£o tem precedente claro
- MudanÃ§a pode afetar comparaÃ§Ã£o com resultados anteriores
- Overhead de compute Ã© muito alto (>2x tempo de treino)
- DecisÃ£o arquitetural tem trade-offs nÃ£o Ã³bvios

**NUNCA perguntar se:**
- SoluÃ§Ã£o estÃ¡ documentada em "ERROS COMUNS"
- Ã‰ tarefa rotineira (criar teste, rodar experimento)
- InformaÃ§Ã£o estÃ¡ disponÃ­vel nos arquivos do projeto

---

## ğŸ“ CONTATO E CONTEXTO

**Projeto:** Mestrado em SegmentaÃ§Ã£o de ROP  
**Dataset:** INRID (81 imagens, 2 classes)  
**Status:** Fase de otimizaÃ§Ã£o (baseline estabelecido)  
**Melhor Modelo:** Wavelet Skip 1 (0.6721 Test Dice)  

**Objetivo Final:** Publicar artigo com modelo state-of-the-art para segmentaÃ§Ã£o de lesÃµes em ROP.

---

**Ãšltima AtualizaÃ§Ã£o:** 2026-01-10  
**VersÃ£o:** 1.0  
**Autor:** Lucas (com assistÃªncia de GitHub Copilot)

---

## ğŸ¯ RESUMO EXECUTIVO (TL;DR)

```
ESTRUTURA: configs/ data_factory/ docs/ experiments/ logs/ models/ notebooks/ outputs/ tests/ utils/

NOMENCLATURA: 
- Experimentos: exp_XXX_description.py
- Logs: training_exp_XXX_description.log
- Testes: test_exp_XXX.py (criar PRIMEIRO!)

WORKFLOW:
1. Criar teste â†’ 2. Criar experimento â†’ 3. Rodar teste â†’ 4. Treinar â†’ 5. Documentar

ERROS COMUNS:
- PyTorch 2.6: weights_only=False
- Multi-label: Sigmoid + BCEWithLogitsLoss (nÃ£o Softmax + CrossEntropy)
- CLAHE: Aplicar em LAB-L, nÃ£o RGB
- GroupKFold: Por paciente
- CV Splits: outputs/cv_splits.json (FROZEN!)

ESTADO ATUAL:
- Melhor: Wavelet Skip 1 (0.6721)
- Baseline: B4 + CLAHE (0.6428)
- Ganho: +4.6%

PRÃ“XIMOS PASSOS:
- exp_001: Wavelet Skip 2
- exp_002: Multi-scale Wavelet
- exp_003: Attention Gates
- exp_006: Larger Image Size (768Ã—768)
```

---

**FIM DAS INSTRUÃ‡Ã•ES**

Boa sorte, novo agente! ğŸš€ VocÃª tem tudo que precisa para continuar este projeto de excelÃªncia.
